{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c221782c-8f53-4536-b0f2-6e231028bf06",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "This notebook evaluates the final machine learning model trained to predict NBA All-Star selections based on player and team performance data. \n",
    "\n",
    "We will load the saved model and test data, generate predictions, and assess performance using classification metrics and visualizations. Finally, we will analyze feature importance to interpret the factors driving model decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "21e8dc30cd10195c",
   "metadata": {},
   "source": [
    "# load saved model\n",
    "with open(\"../models/all_star_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# load test data\n",
    "X_test = pd.read_pickle(\"../data/clean/X_test.pkl\")\n",
    "y_test = pd.read_pickle(\"../data/clean/y_test.pkl\")\n",
    "\n",
    "# define feature columns\n",
    "feature_cols = X_test.columns\n",
    "\n",
    "# if model is logistic regression, load and apply the saved scaler\n",
    "if isinstance(model, LogisticRegression):\n",
    "    with open(\"../models/logreg_scaler.pkl\", \"rb\") as f:\n",
    "        scaler = pickle.load(f)\n",
    "    X_test = scaler.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "afef6665e6a27df8",
   "metadata": {},
   "source": [
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# print classification report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c3ec817436afc54",
   "metadata": {},
   "source": [
    "The detailed metrics above give a numeric summary of model performance. Next, we’ll visualize these results to better understand how the model performs across different classes."
   ]
  },
  {
   "cell_type": "code",
   "id": "8f9a4596284da9e5",
   "metadata": {},
   "source": [
    "cm_norm = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "sns.heatmap(cm_norm, annot=True, fmt=\".2%\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Not All-Star\", \"All-Star\"],\n",
    "            yticklabels=[\"Not All-Star\", \"All-Star\"])\n",
    "plt.title(\"Normalized Confusion Matrix Heatmap\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5692afe96c181549",
   "metadata": {},
   "source": [
    "The normalized confusion matrix shows the model’s performance broken down by actual class.\n",
    "- The model correctly identifies 96.79% of players who were not All-Stars, demonstrating strong specificity and a low false positive rate (1.21%).\n",
    "- For actual All-Stars, the model correctly predicts 66.25% of them, reflecting moderate recall. However, it misses about 33.75% of All-Stars, indicating some false negatives.\n",
    "\n",
    "This means the model is very effective at ruling out non-All-Stars but less effective at capturing every deserving All-Star. The tradeoff between precision and recall is typical in imbalanced classification problems like this. These results highlight the model’s ability to support the project goal of identifying standout players based on performance data, though there remains room to improve recall to capture more true All-Stars."
   ]
  },
  {
   "cell_type": "code",
   "id": "20fabe03-4e94-4fe6-988c-9ede795eb953",
   "metadata": {},
   "source": [
    "coef = pd.Series(model.coef_[0], index=feature_cols)\n",
    "coef = coef.sort_values(key=abs, ascending=False).head(10)\n",
    "coef.plot(kind='barh', color='skyblue')\n",
    "plt.title(\"Top 10 Logistic Regression Coefficients\")\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "58b1866d-b7fb-4f50-8317-296c414b6ea7",
   "metadata": {},
   "source": [
    "Interestingly, the games played feature (`g`) has a strong negative coefficient, which is counterintuitive. While we might expect players who appear in more games to be more likely All-Stars, this may reflect multicollinearity with minutes or points, or patterns where role players log full seasons without standout impact. Let's do a quick check for multicollinearity. "
   ]
  },
  {
   "cell_type": "code",
   "id": "d8de60d6-1fd6-4dfd-8dcb-2f340a65f98a",
   "metadata": {},
   "source": [
    "X = pd.read_pickle(\"../data/clean/X_data.pkl\")\n",
    "X.corr()[\"g\"].abs().drop(\"g\").sort_values(ascending=False).head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cfece895-1571-407d-92cb-a1445f103d34",
   "metadata": {},
   "source": [
    "sns.heatmap(X[[\"g\", \"mp\", \"pts\"]].corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap: Games Played, Minutes, and Points\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d79e551c-5f9c-4dae-9e5f-d4d0a02fdc63",
   "metadata": {},
   "source": [
    "`g` is highly correlated with other features (chiefly `mp`), which may explain the negative coefficient due to multicollinearity. This does not necessarily mean the feature is unimportant--just that its unique contribution to the model is limited after accounting for other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c12de6f-efa2-4e29-857a-59476ecc6ef0",
   "metadata": {},
   "source": [
    "## Model Evaluation Summary\n",
    "\n",
    "The final Logistic Regression model was trained to predict NBA All-Star selections using season-level player and team data. On the test set, the model achieved strong overall performance:\n",
    "\n",
    "- **Accuracy**: 97%\n",
    "- **Precision (All-Star)**: 78%\n",
    "- **Recall (All-Star)**: 66%\n",
    "- **F1 Score (All-Star)**: 0.71\n",
    "\n",
    "The normalized confusion matrix confirmed the model’s strengths in correctly identifying non-All-Stars (96.8%) and its moderate effectiveness in capturing actual All-Stars (66.3%).\n",
    "\n",
    "A feature importance analysis showed that scoring metrics such as points and free throws had strong positive influence on All-Star prediction, while **games played** exhibited an unexpected negative coefficient. A brief investigation into multicollinearity suggested this may result from overlap with other time-based stats like minutes played.\n",
    "\n",
    "These results support the project’s goal of predicting NBA All-Star selections using performance data. While the model prioritizes precision, it still identifies a majority of actual All-Stars and offers a strong baseline for future improvement. With its simplicity and transparency, this model helps surface which player stats are most closely tied to All-Star recognition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
